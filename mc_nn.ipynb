{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mc_nn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZLX5bfvuvJBg",
        "outputId": "0ad36d81-f4ff-44df-9af2-d7abde9abe30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# !unzip robohearts.zip\n",
        "%cd robohearts/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'robohearts/'\n",
            "/content/robohearts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQFmIAWEj30z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import multiprocessing\n",
        "from gymhearts.Hearts import *\n",
        "from gymhearts.Agent.human import Human\n",
        "from gymhearts.Agent.random_agent import RandomAgent\n",
        "from gymhearts.Agent.monte_carlo_nn import MonteCarloNN\n",
        "from gymhearts.Agent.hand_approx import save_model\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsPqUNz_j307",
        "colab_type": "code",
        "outputId": "a65dba0d-6a6e-4f61-eb01-803f2022b763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "NUM_TESTS = 10\n",
        "NUM_EPISODES = 1000\n",
        "TRAINING_ITERS = 10000\n",
        "MAX_SCORE = 100\n",
        "\n",
        "run_train = True\n",
        "\n",
        "playersNameList = ['MonteCarlo', 'Rando', 'Randy', 'Randall']\n",
        "agent_list = [0, 0, 0, 0]\n",
        "\n",
        "# Human vs Random\n",
        "mc_config = {\n",
        "    'print_info' : False,\n",
        "    'epsilon' : .05,\n",
        "    'gamma' : 0.8,\n",
        "    'alpha': 1e-4,\n",
        "    'lr': 1e-3,\n",
        "}\n",
        "agent_list[0] = MonteCarloNN(playersNameList[0], mc_config)\n",
        "agent_list[1] = RandomAgent(playersNameList[1], {'print_info' : False})\n",
        "agent_list[2] = RandomAgent(playersNameList[2], {'print_info' : False})\n",
        "agent_list[3] = RandomAgent(playersNameList[3], {'print_info' : False})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "I am here!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt8mEPEQj31D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAIN THE MONTE CARLO AGENT\n",
        "env = gym.make('Hearts_Card_Game-v0')\n",
        "env.__init__(playersNameList, MAX_SCORE)\n",
        "if run_train:\n",
        "    for trn_episode in tqdm_notebook(range(TRAINING_ITERS)):\n",
        "        observation = env.reset()\n",
        "        history = []\n",
        "        while True:\n",
        "            #env.render()\n",
        "\n",
        "            now_event = observation['event_name']\n",
        "            IsBroadcast = observation['broadcast']\n",
        "            # update my agent before clearing state\n",
        "            if now_event == 'RoundEnd':\n",
        "                agent_list[0].update_weights(history, -reward['MonteCarlo'])\n",
        "                history = []\n",
        "            if now_event == 'GameOver':\n",
        "                  break\n",
        "            if observation['event_name']=='PlayTrick' and observation['data']['playerName'] == 'MonteCarlo':\n",
        "                # don't add score, they don't change till at end of round\n",
        "                history.append((observation, agent_list[0].played_cards, agent_list[0].won_cards))\n",
        "\n",
        "            action = None\n",
        "            if IsBroadcast == True:\n",
        "                for agent in agent_list:\n",
        "                    agent.Do_Action(observation)\n",
        "            else:\n",
        "                playName = observation['data']['playerName']\n",
        "                for agent in agent_list:\n",
        "                    if agent.name == playName:\n",
        "                        action = agent.Do_Action(observation)\n",
        "\n",
        "            observation, reward, done, info = env.step(action)\n",
        "    save_model(agent_list[0].nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX6qQi9blVFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_test(num_won):\n",
        "    # Weird hack to make progress bars render properly\n",
        "    print(' ', end='', flush=True)\n",
        "    for i_ep in tqdm_notebook(range(NUM_EPISODES)):\n",
        "        observation = env.reset()\n",
        "        while True:\n",
        "            now_event = observation['event_name']\n",
        "            IsBroadcast = observation['broadcast']\n",
        "            action = None\n",
        "            if IsBroadcast == True:\n",
        "                for agent in agent_list:\n",
        "                    agent.Do_Action(observation)\n",
        "            else:\n",
        "                playName = observation['data']['playerName']\n",
        "                for agent in agent_list:\n",
        "                    if agent.name == playName:\n",
        "                        action = agent.Do_Action(observation)\n",
        "            if now_event == 'GameOver':\n",
        "                num_won += int(observation['data']['Winner'] == 'MonteCarlo')\n",
        "                break\n",
        "            observation, reward, done, info = env.step(action)\n",
        "    return num_won"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qn-MK5D5pBUw",
        "colab": {}
      },
      "source": [
        "# Uncomment this line for pretrained weights\n",
        "# weights = [-0.46031637, -1.02296217, -1.64597146, 0.50871499, 0.05907032, -0.04527117,\n",
        "# -2.67590788, -1.78400492, -0.08667306, 0.48108891, 0.66066313, -1.57675411,\n",
        "# -0.56494518, -0.07736412, -0.3257198, -0.65003209, -0.63740714, 0.44494984,\n",
        "# -0.1545964, 0.67457139, 2.31472314, 0.8694452, -2.29173301, 0.52783125,\n",
        "# -0.86950875, -1.77655688, -3.29970913, -0.242993, -1.57548922, -1.34238258,\n",
        "# 0.36816378, -3.23065985, -0.07919411, -2.1089143, -3.12815169, -0.74580836,\n",
        "# 0.98398675, -0.75271283, -0.81051661, -0.60567687, -3.42010519, -0.63186969,\n",
        "# -2.02352157, -0.27534069, -0.28736574, -1.15836776, -3.28679005, -0.33767846,\n",
        "# -0.41568405, 0.2782292, -1.23761129, -1.80559854]\n",
        "\n",
        "# EVALUATE THE MONTE CARLO AGENT\n",
        "    \n",
        "env = gym.make('Hearts_Card_Game-v0')\n",
        "env.__init__(playersNameList, MAX_SCORE)\n",
        "agent_list[0] = MonteCarloNN(playersNameList[0], params={'nn_path': 'mlp'})\n",
        "mc_wins = [0] * NUM_TESTS        \n",
        "pool = multiprocessing.Pool(processes=NUM_TESTS)\n",
        "mc_wins = pool.map(run_test, mc_wins)\n",
        "print(mc_wins)\n",
        "pool.close()\n",
        "pool.join()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y1WTLbOEYw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_test_2(num_won):\n",
        "    # Weird hack to make progress bars render properly\n",
        "    print(' ', end='', flush=True)\n",
        "    for i_ep in tqdm_notebook(range(NUM_EPISODES)):\n",
        "        observation = env.reset()\n",
        "        while True:\n",
        "            now_event = observation['event_name']\n",
        "            IsBroadcast = observation['broadcast']\n",
        "            action = None\n",
        "            if IsBroadcast == True:\n",
        "                for agent in agent_list:\n",
        "                    agent.Do_Action(observation)\n",
        "            else:\n",
        "                playName = observation['data']['playerName']\n",
        "                for agent in agent_list:\n",
        "                    if agent.name == playName:\n",
        "                        action = agent.Do_Action(observation)\n",
        "            if now_event == 'GameOver':\n",
        "                num_won += int(observation['data']['Winner'] == 'Randman')\n",
        "                break\n",
        "            observation, reward, done, info = env.step(action)\n",
        "    return num_won"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-b3qOJsbh9pf",
        "colab": {}
      },
      "source": [
        "# EVALUATE THE RANDOM AGENT\n",
        "env = gym.make('Hearts_Card_Game-v0')\n",
        "env.__init__(playersNameList, MAX_SCORE)\n",
        "playersNameList[0] = 'Randman'\n",
        "agent_list[0] = RandomAgent(playersNameList[0])\n",
        "rand_wins = [0] * NUM_TESTS\n",
        "        \n",
        "pool = multiprocessing.Pool(processes=NUM_TESTS)\n",
        "rand_wins = pool.map(run_test_2, rand_wins)\n",
        "print(rand_wins)\n",
        "pool.close()\n",
        "pool.join()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3kXj1tPLnR7F",
        "colab": {}
      },
      "source": [
        "print(f\"Monte Carlo won {sum(mc_wins)/len(mc_wins)} times on average :: {str(mc_wins)}\")\n",
        "print(f\"Random won {sum(rand_wins)/len(rand_wins)} times on average :: {str(rand_wins)}\")\n",
        "# print(f\"\\n\\nThe Monte Carlo weights are: {str(weights)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}